{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNcE1XohLm817ASR4jOLqpa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"XCluirgbDlTC","executionInfo":{"status":"ok","timestamp":1747051120861,"user_tz":-330,"elapsed":16528,"user":{"displayName":"Manas Varma","userId":"03585303840663040031"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim"]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Resize(32),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n","\n","testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n","\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)"],"metadata":{"id":"Q_uA-JmrEkOm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747051128465,"user_tz":-330,"elapsed":7609,"user":{"displayName":"Manas Varma","userId":"03585303840663040031"}},"outputId":"9a7d33c2-a185-4c36-9dc8-d162c0418eb5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:03<00:00, 43.5MB/s]\n"]}]},{"cell_type":"code","source":["class BasicBlock(nn.Module):\n","  def __init__(self, in_channels, out_channels, stride=1):\n","    super(BasicBlock, self).__init__()\n","    self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n","    self.bn1 = nn.BatchNorm2d(out_channels)\n","    self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n","    self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","    self.shortcut = nn.Sequential()\n","    if stride !=1 or in_channels != out_channels:\n","      self.shortcut = nn.Sequential(\n","          nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","          nn.BatchNorm2d(out_channels)\n","      )\n","\n","  def forward(self, x):\n","    out = F.relu(self.bn1(self.conv1(x)))\n","    out = self.bn2(self.conv2(out))\n","    out += self.shortcut(x)\n","    return F.relu(out)"],"metadata":{"id":"PKN9R0GVXa5o","executionInfo":{"status":"ok","timestamp":1747051128471,"user_tz":-330,"elapsed":5,"user":{"displayName":"Manas Varma","userId":"03585303840663040031"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class ResNet(nn.Module):\n","  def __init__(self, block, num_blocks, num_classes=10):\n","    super(ResNet, self).__init__()\n","    self.in_channels = 64\n","\n","    self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1, bias=False)\n","    self.bn1 = nn.BatchNorm2d(64)\n","\n","    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","\n","    self.linear = nn.Linear(512, num_classes)\n","\n","  def _make_layer(self, block, out_channels, num_blocks, stride):\n","    strides = [stride] + [1] * (num_blocks - 1)\n","\n","    layers = []\n","\n","    for s in strides:\n","      layers.append(block(self.in_channels, out_channels, s))\n","      self.in_channels = out_channels\n","\n","    return nn.Sequential(*layers)\n","\n","  def forward(self, x):\n","    out = F.relu(self.bn1(self.conv1(x)))\n","    out = self.layer1(out)\n","    out = self.layer2(out)\n","    out = self.layer3(out)\n","    out = self.layer4(out)\n","    out = F.avg_pool2d(out, 4)\n","    out = out.view(out.size(0), -1)\n","    out = self.linear(out)\n","    return out\n","\n","def ResNet18():\n","  return ResNet(BasicBlock, [2, 2, 2, 2])"],"metadata":{"id":"tgG4WWO2ftbA","executionInfo":{"status":"ok","timestamp":1747051128481,"user_tz":-330,"elapsed":6,"user":{"displayName":"Manas Varma","userId":"03585303840663040031"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda')\n","model = ResNet18().to(device)\n","lossfn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"metadata":{"id":"8mL3FK1Qwxoc","executionInfo":{"status":"ok","timestamp":1747051128490,"user_tz":-330,"elapsed":4,"user":{"displayName":"Manas Varma","userId":"03585303840663040031"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["epochs = 50\n","train_accs = []\n","train_losses = []\n","\n","for epoch in range(epochs):\n","  model.train()\n","  running_loss = 0.0\n","  correct = 0\n","  total = 0\n","\n","  for data in trainloader:\n","    inputs, labels = data[0].to(device), data[1].to(device)\n","\n","    optimizer.zero_grad()\n","    outputs = model(inputs)\n","    loss = lossfn(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    running_loss += loss.item()\n","    _, predicted = outputs.max(1)\n","    total += labels.size(0)\n","    correct += predicted.eq(labels).sum().item()\n","\n","    epoch_loss = running_loss / len(trainloader)\n","    epoch_acc = 100. * correct / total\n","\n","    train_losses.append(epoch_loss)\n","    train_accs.append(epoch_acc)\n","\n","  print(f\"Epoch {epoch+1}: Loss={epoch_loss:.4f}, Accuracy={epoch_acc:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"grzVXdxShUse","outputId":"3d67cebb-3b2e-48b7-d552-a0a100951df7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Loss=1.2706, Accuracy=53.76%\n","Epoch 2: Loss=0.7794, Accuracy=72.49%\n","Epoch 3: Loss=0.5753, Accuracy=79.89%\n","Epoch 4: Loss=0.4483, Accuracy=84.25%\n"]}]},{"cell_type":"code","source":["os.makedirs(\"checkpoints\", exist_ok=True)\n","torch.save(model.state_dict(), \"checkpoints/resnet18_cifar10.pth\")"],"metadata":{"id":"_4QCfkn_BY92"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","  for data in testloader:\n","    images, labels = data[0].to(device), data[1].to(device)\n","    outputs = model(images)\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","\n","print(f\"Accuracy: {100 * correct / total:.2f}%\")"],"metadata":{"id":"h4p7qJLd3GFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(train_accs, label='Train Accuracy')\n","plt.plot(train_losses, label='Train Loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.savefig(\"assets/training_curve.png\")\n","plt.show()"],"metadata":{"id":"LI8VeSu-USMH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"i3cNrryWsoGX"},"execution_count":null,"outputs":[]}]}